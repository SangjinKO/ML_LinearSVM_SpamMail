{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"colab":{"name":"ML_SVM_SpamMail.ipynb","provenance":[{"file_id":"1AWN_GyX46pkZxT0eS5epAPTv7oklWRKH","timestamp":1582480377005}],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"id":"mdVPU9EUXvij","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"l_hXFEKy2JA6","colab_type":"code","colab":{}},"source":["import sys\n","import os\n","\n","import numpy as np\n","import re\n","import matplotlib.pyplot as plt\n","from scipy.io import loadmat\n","import utils\n","\n","# Enable auto reload\n","%load_ext autoreload\n","%autoreload 2\n","%matplotlib inline\n","\n","# Data Reference: [SpamAssassin Public Corpus](http://spamassassin.apache.org/old/publiccorpus/). "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"93LA_EsbCN1h","colab_type":"code","colab":{}},"source":["def getVocabList():\n","    vocabList = np.genfromtxt(os.path.join('/content/drive/My Drive/Data', 'vocab.txt'), dtype=object)\n","    return list(vocabList[:, 1].astype(str))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rTMDssQ22JB2","colab_type":"code","colab":{}},"source":["def process_email(email_contents, verbose=True):\n","   \n","    # Load Vocabulary\n","    vocabList = getVocabList()\n","\n","    # Init return value\n","    word_indices = []\n","\n","    # ========================== Preprocess Email ===========================\n","    # Find the Headers ( \\n\\n and remove )\n","    # Uncomment the following lines if you are working with raw emails with the\n","    # full headers\n","    # hdrstart = email_contents.find(chr(10) + chr(10))\n","    # email_contents = email_contents[hdrstart:]\n","\n","    # Lower case\n","    email_contents = email_contents.lower()\n","    \n","    # Strip all HTML\n","    # Looks for any expression that starts with < and ends with > and replace\n","    # and does not have any < or > in the tag it with a space\n","    email_contents =re.compile('<[^<>]+>').sub(' ', email_contents)\n","\n","    # Handle Numbers\n","    # Look for one or more characters between 0-9\n","    email_contents = re.compile('[0-9]+').sub(' number ', email_contents)\n","\n","    # Handle URLS\n","    # Look for strings starting with http:// or https://\n","    email_contents = re.compile('(http|https)://[^\\s]*').sub(' httpaddr ', email_contents)\n","\n","    # Handle Email Addresses\n","    # Look for strings with @ in the middle\n","    email_contents = re.compile('[^\\s]+@[^\\s]+').sub(' emailaddr ', email_contents)\n","    \n","    # Handle $ sign\n","    email_contents = re.compile('[$]+').sub(' dollar ', email_contents)\n","    \n","    # get rid of any punctuation\n","    email_contents = re.split('[ @$/#.-:&*+=\\[\\]?!(){},''\">_<;%\\n\\r]', email_contents)\n","\n","    # remove any empty word string\n","    email_contents = [word for word in email_contents if len(word) > 0]\n","    \n","    # Stem the email contents word by word\n","    stemmer = utils.PorterStemmer()\n","    processed_email = []\n","    \n","    for word in email_contents:\n","        # Remove any remaining non alphanumeric characters in word\n","        word = re.compile('[^a-zA-Z0-9]').sub('', word).strip()\n","        word = stemmer.stem(word)\n","        processed_email.append(word)\n","\n","        if len(word) < 1:\n","            continue    \n","        try:\n","          word_indices.append(vocabList.index(word))\n","        except ValueError:\n","          pass\n","          \n","    if verbose:\n","        print('----------------')\n","        print('Processed email:')\n","        print('----------------')\n","        print(' '.join(processed_email))\n","    return word_indices"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"O3e0nR3m2JB6","colab_type":"code","colab":{}},"source":["# Extract Features\n","with open(os.path.join('/content/drive/My Drive/Data', 'emailSample1.txt')) as fid:\n","    file_contents = fid.read()\n","\n","word_indices  = process_email(file_contents)\n","\n","#Print Stats\n","print('-------------')\n","print('Word Indices:')\n","print('-------------')\n","print(word_indices)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"W9AkZHqx2JB-","colab_type":"code","colab":{}},"source":["def email_features(word_indices):\n","    \n","    # Total number of words in the dictionary\n","    n = 1899\n","\n","    x = np.zeros(n)\n","\n","    for idx in range(n):\n","      if idx in word_indices:\n","        x[idx] = 1\n","    return x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hx2-Y1iG2JCC","colab_type":"code","colab":{}},"source":["# Extract Features\n","with open(os.path.join('/content/drive/My Drive/Data', 'emailSample1.txt')) as fid:\n","    file_contents = fid.read()\n","\n","word_indices  = process_email(file_contents)\n","features      = email_features(word_indices)\n","\n","# Print Stats\n","print('\\nLength of feature vector: %d' % len(features))\n","print('Number of non-zero entries: %d' % sum(features > 0))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qy5WZClL2JCG","colab_type":"code","colab":{}},"source":["### Training SVM for Spam Classification\n","\n","# Load the Spam Email dataset\n","# You will have X, y in your environment\n","data = loadmat(os.path.join('/content/drive/My Drive/Data', 'spamTrain.mat'))\n","X, y= data['X'].astype(float), data['y'][:, 0]\n","\n","print('Training Linear SVM (Spam Classification)')\n","\n","C = 0.1\n","model = LinearSVC(C=C, penalty='l2', loss='hinge', random_state=5566)\n","model.fit(X, y)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zj48Kt3E2JCJ","colab_type":"code","colab":{}},"source":["# Load the test dataset\n","# You will have Xtest, ytest in your environment\n","data = loadmat(os.path.join('/content/drive/My Drive/Data', 'spamTest.mat'))\n","Xtest, ytest = data['Xtest'].astype(float), data['ytest'][:, 0]\n","\n","print('Evaluating the trained Linear SVM on a test set ...')\n","p = model.predict(Xtest)\n","\n","print('Test Accuracy: %.2f' % (np.mean(p == ytest) * 100))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AK4HZ2q92JCL","colab_type":"code","colab":{}},"source":["# Sort the weights and obtin the vocabulary list\n","\n","weights = model.coef_[0]\n","\n","idx = np.argsort(weights)\n","top_idx = idx[-15:][::-1]\n","vocabList = getVocabList()\n","\n","print('Top predictors of spam:')\n","print('%-15s %-15s' % ('word', 'weight'))\n","print('----' + ' '*12 + '------')\n","for word, w in zip(np.array(vocabList)[top_idx], weights[top_idx]):\n","    print('%-15s %0.2f' % (word, w))\n"],"execution_count":0,"outputs":[]}]}